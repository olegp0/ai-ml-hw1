# Сервис предсказания цены авто

## Эксперименты

Все эксперименты у меня прописаны в `.ipynb`-файле с соответствующей аналитикой, тут же я просто отражу основные результаты и краткие выводы


1) `exp_0_mean` | `Задание 9`
	* **Описание:** регрессия оптимальной константой -- в нашем случае это среднее
	* **Метрики:**
		```
		TRAIN:
		    R2:    0.0000
		    MSE:   286638338357.8865
		    RMSE:  535386.1582

		TEST:
		    R2:    -0.0157
		    MSE:   583842339797.0208
		    RMSE:  764095.7661
		```
	* **Выводы:** ну, ожидаемо 

2) `exp_1_OLS` | `Задание 9`
	* **Описание:** обычная регрессия, она же обычные квадраты, она же метод наименьших квадратов -- просто вычисление таргета по формуле
	* **Метрики:**
		```
		TRAIN:
		    R2:    0.5923
		    MSE:   116874153930.0288
		    RMSE:  341868.6209

		TEST:
		    R2:    0.5941
		    MSE:   233298779730.4571
		    RMSE:  483010.1238
		```
	* **Выводы:** что-то адекватное обучили, по сравнению с константным прогнозов значительно уронили среднюю ошибку

3) `exp_2_OLS_scaled` | `Задание 10`
	* **Описание:** OLS на стандартизированных данных
	* **Метрики:**
		```
		TRAIN:
		    R2:    0.5923
		    MSE:   116874153930.0289
		    RMSE:  341868.6209

		TEST:
		    R2:    0.5941
		    MSE:   233298779730.4498
		    RMSE:  483010.1238
		```
	* **Выводы:** все то же самое, стандартизация не дала эффекта. Зато узнали, что признак с наибольшим вкладом -- `max_power`

4) `exp_3_Lasso_scaled` | `Задание 12`
	* **Описание:** Lasso-регрессия на стандартизированных данных
	* **Метрики:**
		```
		TRAIN:
		    R2:    0.5923
		    MSE:   116874153940.1429
		    RMSE:  341868.6209

		TEST:
		    R2:    0.5941
		    MSE:   233299450599.1693
		    RMSE:  483010.8183
		```
	* **Выводы:** параметр регуляризации по умолчанию в общем-то особо и не регуляризирует -- переобучения нет, веса не улетают в космос, отсюда и такой результат. Никакой признак не занулился.

5) `exp_4_Lasso` | `Задание 12`
	* **Описание:** Lasso-регрессия без стандартизации
	* **Метрики:**
		```
		TRAIN:
		    R2:    0.5923
		    MSE:   116874153932.2977
		    RMSE:  341868.6209

		TEST:
		    R2:    0.5941
		    MSE:   233298939031.5297
		    RMSE:  483010.2887
		```
	* **Выводы:** из-за более существенного масштаба и не слишком высокого влияния занулились признаки пробега и объема двигателя.

6) `exp_5_Lasso_GS_scaled` | `Задание 13`
	* **Описание:** Lasso-регрессия на стандартизированных данных с оптимизацией регуляризации по сетке на `cv=10`
	* **Метрики:**
		```
		TRAIN:
		    R2:    0.5923
		    MSE:   116874252567.1795
		    RMSE:  341868.7651

		TEST:
		    R2:    0.5940
		    MSE:   233365851675.2124
		    RMSE:  483079.5500
		```
	* **Выводы:** оптимальный параметр -- 100 (максимальное значение по моей сетке). Никакой признак не занулился, что в принципе ожидаемо с учетом предыдущих экспериментов.

7) `exp_6_ElasticNet_GS_scaled` | `Задание 13`
	* **Описание:** ElasticNet-регрессия на стандартизированных данных с оптимизацией регуляризации по сетке на `cv=10`
	* **Метрики:**
		```
		TRAIN:
		    R2:    0.5923
		    MSE:   116874252567.1795
		    RMSE:  341868.7651

		TEST:
		    R2:    0.5940
		    MSE:   233365851675.2124
		    RMSE:  483079.5500
		```
	* **Выводы:** оптимальный параметр -- `alpha=100`, `lr_ratio=1` (максимальнй значения по моей сетке). Ровно то же самое на выходе.

8) `exp_7_Ridge_GS_scaled_categories` | `Задание 16`
	* **Описание:** Ridge-регрессия на стандартизированных данных и OHE-категориях с оптимизацией регуляризации по сетке на `cv=10`
	* **Метрики:**
		```
		TRAIN:
		    R2:    0.6493
		    MSE:   100512085773.0842
		    RMSE:  317036.4108

		TEST:
		    R2:    0.6196
		    MSE:   218686405126.1404
		    RMSE:  467639.1826
		```
	* **Выводы:** оптимальный параметр -- `alpha=0.001` (минимальное значение по моей сетке). Стало чуть лучше просто потому что накинули больше данных. Регуляризация тут смысла абсолютно не имеет, так как по сути оптимизируемый параметр стремится к нулю, т.е. к OLS.

**Общие выводы:** проделали бесполезную работу, где все модели похожи друг на друга. Все понял, но совершенно неинтересно. Было бы приятнее, если бы задачки предполагали какой-то самостоятельный инжинириг признаков, но имеем что имеем. Данные простые, модели тоже, о результатах особо сказать нечего так как они практически не меняются от модели к модели.


## Бизнес-метрика

| Название эксперимента             | Train  | Test   |
| --------------------------------- | -------| ------ |
| exp_0_mean                        | 11.75% | 11.00% |
| exp_1_OLS                         | 21.52% | 22.70% |
| exp_2_OLS_scaled                  | 21.52% | 22.70% |
| exp_3_Lasso_scaled                | 21.52% | 22.70% |
| exp_4_Lasso                       | 21.52% | 22.70% |
| exp_5_Lasso_GS_scaled             | 21.52% | 22.60% |
| exp_6_ElasticNet_GS_scaled        | 21.52% | 22.60% |
| exp_7_Ridge_GS_scaled_categories  | 21.11% | 23.60% |

**Выводы:** ровно те же, что я и писал выше. Для сервиса берем последнюю модель, так как на тесте у нее наилучший показатель.


# FastAPI-приложение

Запуск: `python hw1_fastapi.py`, далее обращаемся по `http://localhost:8000`

Примеры работы в `.ipynb`-файле в разделе задания 18 части 3
